// -----// IR Dump Before DecomposeComplexOps (torch-decompose-complex-ops) //----- //
func.func @prefill_bs1(%arg0: !torch.vtensor<[1,?],si64>, %arg1: !torch.vtensor<[1],si64>, %arg2: !torch.vtensor<[1,?],si64>, %arg3: !torch.vtensor<[?,49152],f16>) -> !torch.vtensor<[1,?,256],f32> attributes {torch.assume_strict_symbolic_shapes} {
  %int256 = torch.constant.int 256
  %float9.000000e00 = torch.constant.float 9.000000e+00
  %int16 = torch.constant.int 16
  %float0.000000e00 = torch.constant.float 0.000000e+00
  %int11 = torch.constant.int 11
  %int0 = torch.constant.int 0
  %none = torch.constant.none
  %true = torch.constant.bool true
  %int2 = torch.constant.int 2
  %int4 = torch.constant.int 4
  %int6 = torch.constant.int 6
  %int-2 = torch.constant.int -2
  %int32 = torch.constant.int 32
  %int1 = torch.constant.int 1
  %false = torch.constant.bool false
  %int-1 = torch.constant.int -1
  %int5 = torch.constant.int 5
  %c32 = arith.constant 32 : index
  %c1 = arith.constant 1 : index
  %0 = torch_c.to_builtin_tensor %arg2 : !torch.vtensor<[1,?],si64> -> tensor<1x?xi64>
  %dim = tensor.dim %0, %c1 : tensor<1x?xi64>
  %1 = torch_c.to_builtin_tensor %arg0 : !torch.vtensor<[1,?],si64> -> tensor<1x?xi64>
  %__auto.token_embd.weight = util.global.load @__auto.token_embd.weight : tensor<256x32xf32>
  %2 = torch_c.from_builtin_tensor %__auto.token_embd.weight : tensor<256x32xf32> -> !torch.vtensor<[256,32],f32>
  %__auto.blk.0.ffn_gate_inp.weight = util.global.load @__auto.blk.0.ffn_gate_inp.weight : tensor<4x32xf32>
  %3 = torch_c.from_builtin_tensor %__auto.blk.0.ffn_gate_inp.weight : tensor<4x32xf32> -> !torch.vtensor<[4,32],f32>
  %__auto.blk.0.ffn_gate_exps.weight = util.global.load @__auto.blk.0.ffn_gate_exps.weight : tensor<4x16x32xf32>
  %4 = torch_c.from_builtin_tensor %__auto.blk.0.ffn_gate_exps.weight : tensor<4x16x32xf32> -> !torch.vtensor<[4,16,32],f32>
  %__auto.blk.0.ffn_up_exps.weight = util.global.load @__auto.blk.0.ffn_up_exps.weight : tensor<4x16x32xf32>
  %5 = torch_c.from_builtin_tensor %__auto.blk.0.ffn_up_exps.weight : tensor<4x16x32xf32> -> !torch.vtensor<[4,16,32],f32>
  %__auto.blk.0.ffn_down_exps.weight = util.global.load @__auto.blk.0.ffn_down_exps.weight : tensor<4x32x16xf32>
  %6 = torch_c.from_builtin_tensor %__auto.blk.0.ffn_down_exps.weight : tensor<4x32x16xf32> -> !torch.vtensor<[4,32,16],f32>
  %__auto.output_norm.weight = util.global.load @__auto.output_norm.weight : tensor<32xf32>
  %7 = torch_c.from_builtin_tensor %__auto.output_norm.weight : tensor<32xf32> -> !torch.vtensor<[32],f32>
  %__auto.output.weight = util.global.load @__auto.output.weight : tensor<256x32xf32>
  %8 = torch_c.from_builtin_tensor %__auto.output.weight : tensor<256x32xf32> -> !torch.vtensor<[256,32],f32>
  %9 = arith.muli %dim, %c32 : index
  %10 = util.assume.int %9<umin = 32, umax = 224, udiv = 32> : index
  %11 = flow.tensor.tie_shape %1 : tensor<1x?xi64>{%10}
  %12 = torch_c.from_builtin_tensor %11 : tensor<1x?xi64> -> !torch.vtensor<[1,?],si64>
  %13 = torch.prims.convert_element_type %2, %int5 : !torch.vtensor<[256,32],f32>, !torch.int -> !torch.vtensor<[256,32],f16>
  %14 = torch.aten.embedding %13, %12, %int-1, %false, %false : !torch.vtensor<[256,32],f16>, !torch.vtensor<[1,?],si64>, !torch.int, !torch.bool, !torch.bool -> !torch.vtensor<[1,?,32],f16>
  %15 = torch.aten.size.int %12, %int1 : !torch.vtensor<[1,?],si64>, !torch.int -> !torch.int
  %16 = torch.prim.ListConstruct %int-1, %int32 : (!torch.int, !torch.int) -> !torch.list<int>
  %17 = torch.aten.view %14, %16 : !torch.vtensor<[1,?,32],f16>, !torch.list<int> -> !torch.vtensor<[?,32],f16>
  %18 = torch.prims.convert_element_type %3, %int5 : !torch.vtensor<[4,32],f32>, !torch.int -> !torch.vtensor<[4,32],f16>
  %19 = torch.aten.transpose.int %18, %int-2, %int-1 : !torch.vtensor<[4,32],f16>, !torch.int, !torch.int -> !torch.vtensor<[32,4],f16>
  %20 = torch.aten.mm %17, %19 : !torch.vtensor<[?,32],f16>, !torch.vtensor<[32,4],f16> -> !torch.vtensor<[?,4],f16>
  %21 = torch.prims.convert_element_type %20, %int6 : !torch.vtensor<[?,4],f16>, !torch.int -> !torch.vtensor<[?,4],f32>
  %22 = torch.aten.sigmoid %21 : !torch.vtensor<[?,4],f32> -> !torch.vtensor<[?,4],f32>
  %23 = torch.prim.ListConstruct %int-1, %int4 : (!torch.int, !torch.int) -> !torch.list<int>
  %24 = torch.aten.view %22, %23 : !torch.vtensor<[?,4],f32>, !torch.list<int> -> !torch.vtensor<[?,4],f32>
  %25 = torch.prim.ListConstruct %int-1, %int2, %int2 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %26 = torch.aten.view %22, %25 : !torch.vtensor<[?,4],f32>, !torch.list<int> -> !torch.vtensor<[?,2,2],f32>
  %values, %indices = torch.aten.topk %26, %int2, %int-1, %true, %true : !torch.vtensor<[?,2,2],f32>, !torch.int, !torch.int, !torch.bool, !torch.bool -> !torch.vtensor<[?,2,2],f32>, !torch.vtensor<[?,2,2],si64>
  %27 = torch.prim.ListConstruct %int-1 : (!torch.int) -> !torch.list<int>
  %28 = torch.aten.sum.dim_IntList %values, %27, %false, %none : !torch.vtensor<[?,2,2],f32>, !torch.list<int>, !torch.bool, !torch.none -> !torch.vtensor<[?,2],f32>
  %values_0, %indices_1 = torch.aten.topk %28, %int1, %int-1, %true, %true : !torch.vtensor<[?,2],f32>, !torch.int, !torch.int, !torch.bool, !torch.bool -> !torch.vtensor<[?,1],f32>, !torch.vtensor<[?,1],si64>
  %29 = torch.aten.zeros_like %28, %none, %none, %none, %false, %int1 : !torch.vtensor<[?,2],f32>, !torch.none, !torch.none, !torch.none, !torch.bool, !torch.int -> !torch.vtensor<[?,2],f32>
  %30 = torch.aten.scatter.value %29, %int1, %indices_1, %int1 : !torch.vtensor<[?,2],f32>, !torch.int, !torch.vtensor<[?,1],si64>, !torch.int -> !torch.vtensor<[?,2],f32>
  %31 = torch.aten.mul.int %15, %int2 : !torch.int, !torch.int -> !torch.int
  %32 = torch.aten.unsqueeze %30, %int-1 : !torch.vtensor<[?,2],f32>, !torch.int -> !torch.vtensor<[?,2,1],f32>
  %33 = torch.prim.ListConstruct %int-1, %int2, %int2 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %34 = torch.aten.expand %32, %33, %false : !torch.vtensor<[?,2,1],f32>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,2,2],f32>
  %35 = torch.prim.ListConstruct %15, %int4 : (!torch.int, !torch.int) -> !torch.list<int>
  %36 = torch.aten._unsafe_view %34, %35 : !torch.vtensor<[?,2,2],f32>, !torch.list<int> -> !torch.vtensor<[?,4],f32>
  %37 = torch.prims.convert_element_type %36, %int11 : !torch.vtensor<[?,4],f32>, !torch.int -> !torch.vtensor<[?,4],i1>
  %38 = torch.aten.bitwise_not %37 : !torch.vtensor<[?,4],i1> -> !torch.vtensor<[?,4],i1>
  %cpu = torch.constant.device "cpu"
  %39 = torch.aten.scalar_tensor %float0.000000e00, %int6, %int0, %cpu, %none : !torch.float, !torch.int, !torch.int, !torch.Device, !torch.none -> !torch.vtensor<[],f32>
  %40 = torch.aten.where.self %38, %39, %24 : !torch.vtensor<[?,4],i1>, !torch.vtensor<[],f32>, !torch.vtensor<[?,4],f32> -> !torch.vtensor<[?,4],f32>
  %values_2, %indices_3 = torch.aten.topk %40, %int2, %int-1, %true, %true : !torch.vtensor<[?,4],f32>, !torch.int, !torch.int, !torch.bool, !torch.bool -> !torch.vtensor<[?,2],f32>, !torch.vtensor<[?,2],si64>
  %41 = torch.prim.ListConstruct %indices_3 : (!torch.vtensor<[?,2],si64>) -> !torch.list<optional<vtensor>>
  %42 = torch.aten.index.Tensor %4, %41 : !torch.vtensor<[4,16,32],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[?,2,16,32],f32>
  %43 = torch.aten.unsqueeze %17, %int1 : !torch.vtensor<[?,32],f16>, !torch.int -> !torch.vtensor<[?,1,32],f16>
  %44 = torch.prim.ListConstruct %15, %int32, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %45 = torch.aten.view %42, %44 : !torch.vtensor<[?,2,16,32],f32>, !torch.list<int> -> !torch.vtensor<[?,32,32],f32>
  %46 = torch.aten.transpose.int %45, %int-2, %int-1 : !torch.vtensor<[?,32,32],f32>, !torch.int, !torch.int -> !torch.vtensor<[?,32,32],f32>
  %47 = torch.prims.convert_element_type %46, %int5 : !torch.vtensor<[?,32,32],f32>, !torch.int -> !torch.vtensor<[?,32,32],f16>
  %48 = torch.prim.ListConstruct %15, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %49 = torch.aten.expand %43, %48, %false : !torch.vtensor<[?,1,32],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,1,32],f16>
  %50 = torch.prim.ListConstruct %15, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %51 = torch.aten.view %49, %50 : !torch.vtensor<[?,1,32],f16>, !torch.list<int> -> !torch.vtensor<[?,1,32],f16>
  %52 = torch.prim.ListConstruct %15, %int32, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %53 = torch.aten.expand %47, %52, %false : !torch.vtensor<[?,32,32],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,32,32],f16>
  %54 = torch.prim.ListConstruct %15, %int32, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %55 = torch.aten.view %53, %54 : !torch.vtensor<[?,32,32],f16>, !torch.list<int> -> !torch.vtensor<[?,32,32],f16>
  %56 = torch.aten.bmm %51, %55 : !torch.vtensor<[?,1,32],f16>, !torch.vtensor<[?,32,32],f16> -> !torch.vtensor<[?,1,32],f16>
  %57 = torch.prim.ListConstruct %15, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %58 = torch.aten.view %56, %57 : !torch.vtensor<[?,1,32],f16>, !torch.list<int> -> !torch.vtensor<[?,1,32],f16>
  %59 = torch.prim.ListConstruct %15, %int2, %int16 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %60 = torch.aten.view %58, %59 : !torch.vtensor<[?,1,32],f16>, !torch.list<int> -> !torch.vtensor<[?,2,16],f16>
  %61 = torch.aten.silu %60 : !torch.vtensor<[?,2,16],f16> -> !torch.vtensor<[?,2,16],f16>
  %62 = torch.prim.ListConstruct %indices_3 : (!torch.vtensor<[?,2],si64>) -> !torch.list<optional<vtensor>>
  %63 = torch.aten.index.Tensor %5, %62 : !torch.vtensor<[4,16,32],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[?,2,16,32],f32>
  %64 = torch.aten.unsqueeze %17, %int1 : !torch.vtensor<[?,32],f16>, !torch.int -> !torch.vtensor<[?,1,32],f16>
  %65 = torch.prim.ListConstruct %15, %int32, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %66 = torch.aten.view %63, %65 : !torch.vtensor<[?,2,16,32],f32>, !torch.list<int> -> !torch.vtensor<[?,32,32],f32>
  %67 = torch.aten.transpose.int %66, %int-2, %int-1 : !torch.vtensor<[?,32,32],f32>, !torch.int, !torch.int -> !torch.vtensor<[?,32,32],f32>
  %68 = torch.prims.convert_element_type %67, %int5 : !torch.vtensor<[?,32,32],f32>, !torch.int -> !torch.vtensor<[?,32,32],f16>
  %69 = torch.prim.ListConstruct %15, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %70 = torch.aten.expand %64, %69, %false : !torch.vtensor<[?,1,32],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,1,32],f16>
  %71 = torch.prim.ListConstruct %15, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %72 = torch.aten.view %70, %71 : !torch.vtensor<[?,1,32],f16>, !torch.list<int> -> !torch.vtensor<[?,1,32],f16>
  %73 = torch.prim.ListConstruct %15, %int32, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %74 = torch.aten.expand %68, %73, %false : !torch.vtensor<[?,32,32],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,32,32],f16>
  %75 = torch.prim.ListConstruct %15, %int32, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %76 = torch.aten.view %74, %75 : !torch.vtensor<[?,32,32],f16>, !torch.list<int> -> !torch.vtensor<[?,32,32],f16>
  %77 = torch.aten.bmm %72, %76 : !torch.vtensor<[?,1,32],f16>, !torch.vtensor<[?,32,32],f16> -> !torch.vtensor<[?,1,32],f16>
  %78 = torch.prim.ListConstruct %15, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %79 = torch.aten.view %77, %78 : !torch.vtensor<[?,1,32],f16>, !torch.list<int> -> !torch.vtensor<[?,1,32],f16>
  %80 = torch.prim.ListConstruct %15, %int2, %int16 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %81 = torch.aten.view %79, %80 : !torch.vtensor<[?,1,32],f16>, !torch.list<int> -> !torch.vtensor<[?,2,16],f16>
  %82 = torch.aten.mul.Tensor %61, %81 : !torch.vtensor<[?,2,16],f16>, !torch.vtensor<[?,2,16],f16> -> !torch.vtensor<[?,2,16],f16>
  %83 = torch.prim.ListConstruct %indices_3 : (!torch.vtensor<[?,2],si64>) -> !torch.list<optional<vtensor>>
  %84 = torch.aten.index.Tensor %6, %83 : !torch.vtensor<[4,32,16],f32>, !torch.list<optional<vtensor>> -> !torch.vtensor<[?,2,32,16],f32>
  %85 = torch.prim.ListConstruct %31, %int1, %int16 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %86 = torch.aten.view %82, %85 : !torch.vtensor<[?,2,16],f16>, !torch.list<int> -> !torch.vtensor<[?,1,16],f16>
  %87 = torch.prim.ListConstruct %31, %int32, %int16 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %88 = torch.aten.view %84, %87 : !torch.vtensor<[?,2,32,16],f32>, !torch.list<int> -> !torch.vtensor<[?,32,16],f32>
  %89 = torch.aten.transpose.int %88, %int-2, %int-1 : !torch.vtensor<[?,32,16],f32>, !torch.int, !torch.int -> !torch.vtensor<[?,16,32],f32>
  %90 = torch.prims.convert_element_type %89, %int5 : !torch.vtensor<[?,16,32],f32>, !torch.int -> !torch.vtensor<[?,16,32],f16>
  %91 = torch.prim.ListConstruct %31, %int1, %int16 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %92 = torch.aten.expand %86, %91, %false : !torch.vtensor<[?,1,16],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,1,16],f16>
  %93 = torch.prim.ListConstruct %31, %int1, %int16 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %94 = torch.aten.view %92, %93 : !torch.vtensor<[?,1,16],f16>, !torch.list<int> -> !torch.vtensor<[?,1,16],f16>
  %95 = torch.prim.ListConstruct %31, %int16, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %96 = torch.aten.expand %90, %95, %false : !torch.vtensor<[?,16,32],f16>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,16,32],f16>
  %97 = torch.prim.ListConstruct %31, %int16, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %98 = torch.aten.view %96, %97 : !torch.vtensor<[?,16,32],f16>, !torch.list<int> -> !torch.vtensor<[?,16,32],f16>
  %99 = torch.aten.bmm %94, %98 : !torch.vtensor<[?,1,16],f16>, !torch.vtensor<[?,16,32],f16> -> !torch.vtensor<[?,1,32],f16>
  %100 = torch.prim.ListConstruct %31, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %101 = torch.aten.view %99, %100 : !torch.vtensor<[?,1,32],f16>, !torch.list<int> -> !torch.vtensor<[?,1,32],f16>
  %102 = torch.prim.ListConstruct %15, %int2, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %103 = torch.aten.view %101, %102 : !torch.vtensor<[?,1,32],f16>, !torch.list<int> -> !torch.vtensor<[?,2,32],f16>
  %104 = torch.prim.ListConstruct %31, %int1, %int1 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %105 = torch.aten.view %values_2, %104 : !torch.vtensor<[?,2],f32>, !torch.list<int> -> !torch.vtensor<[?,1,1],f32>
  %106 = torch.prim.ListConstruct %31, %int32, %int1 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %107 = torch.aten.view %103, %106 : !torch.vtensor<[?,2,32],f16>, !torch.list<int> -> !torch.vtensor<[?,32,1],f16>
  %108 = torch.aten.transpose.int %107, %int-2, %int-1 : !torch.vtensor<[?,32,1],f16>, !torch.int, !torch.int -> !torch.vtensor<[?,1,32],f16>
  %109 = torch.prims.convert_element_type %108, %int6 : !torch.vtensor<[?,1,32],f16>, !torch.int -> !torch.vtensor<[?,1,32],f32>
  %110 = torch.prim.ListConstruct %31, %int1, %int1 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %111 = torch.aten.expand %105, %110, %false : !torch.vtensor<[?,1,1],f32>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,1,1],f32>
  %112 = torch.prim.ListConstruct %31, %int1, %int1 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %113 = torch.aten.view %111, %112 : !torch.vtensor<[?,1,1],f32>, !torch.list<int> -> !torch.vtensor<[?,1,1],f32>
  %114 = torch.prim.ListConstruct %31, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %115 = torch.aten.expand %109, %114, %false : !torch.vtensor<[?,1,32],f32>, !torch.list<int>, !torch.bool -> !torch.vtensor<[?,1,32],f32>
  %116 = torch.prim.ListConstruct %31, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %117 = torch.aten.view %115, %116 : !torch.vtensor<[?,1,32],f32>, !torch.list<int> -> !torch.vtensor<[?,1,32],f32>
  %118 = torch.aten.bmm %113, %117 : !torch.vtensor<[?,1,1],f32>, !torch.vtensor<[?,1,32],f32> -> !torch.vtensor<[?,1,32],f32>
  %119 = torch.prim.ListConstruct %31, %int1, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %120 = torch.aten.view %118, %119 : !torch.vtensor<[?,1,32],f32>, !torch.list<int> -> !torch.vtensor<[?,1,32],f32>
  %121 = torch.prim.ListConstruct %15, %int2, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %122 = torch.aten.view %120, %121 : !torch.vtensor<[?,1,32],f32>, !torch.list<int> -> !torch.vtensor<[?,2,32],f32>
  %123 = torch.prim.ListConstruct %int1 : (!torch.int) -> !torch.list<int>
  %124 = torch.aten.sum.dim_IntList %122, %123, %false, %none : !torch.vtensor<[?,2,32],f32>, !torch.list<int>, !torch.bool, !torch.none -> !torch.vtensor<[?,32],f32>
  %125 = torch.prim.ListConstruct %int1, %15, %int32 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %126 = torch.aten.view %124, %125 : !torch.vtensor<[?,32],f32>, !torch.list<int> -> !torch.vtensor<[1,?,32],f32>
  %127 = torch.aten.pow.Tensor_Scalar %126, %int2 : !torch.vtensor<[1,?,32],f32>, !torch.int -> !torch.vtensor<[1,?,32],f32>
  %128 = torch.prim.ListConstruct %int-1 : (!torch.int) -> !torch.list<int>
  %129 = torch.aten.mean.dim %127, %128, %true, %none : !torch.vtensor<[1,?,32],f32>, !torch.list<int>, !torch.bool, !torch.none -> !torch.vtensor<[1,?,1],f32>
  %130 = torch.aten.add.Scalar %129, %float9.000000e00, %int1 : !torch.vtensor<[1,?,1],f32>, !torch.float, !torch.int -> !torch.vtensor<[1,?,1],f32>
  %131 = torch.aten.rsqrt %130 : !torch.vtensor<[1,?,1],f32> -> !torch.vtensor<[1,?,1],f32>
  %132 = torch.aten.mul.Tensor %126, %131 : !torch.vtensor<[1,?,32],f32>, !torch.vtensor<[1,?,1],f32> -> !torch.vtensor<[1,?,32],f32>
  %133 = torch.aten.mul.Tensor %7, %132 : !torch.vtensor<[32],f32>, !torch.vtensor<[1,?,32],f32> -> !torch.vtensor<[1,?,32],f32>
  %134 = torch.aten.transpose.int %8, %int-2, %int-1 : !torch.vtensor<[256,32],f32>, !torch.int, !torch.int -> !torch.vtensor<[32,256],f32>
  %135 = torch.prim.ListConstruct %15, %int32 : (!torch.int, !torch.int) -> !torch.list<int>
  %136 = torch.aten.view %133, %135 : !torch.vtensor<[1,?,32],f32>, !torch.list<int> -> !torch.vtensor<[?,32],f32>
  %137 = torch.aten.mm %136, %134 : !torch.vtensor<[?,32],f32>, !torch.vtensor<[32,256],f32> -> !torch.vtensor<[?,256],f32>
  %138 = torch.prim.ListConstruct %int1, %15, %int256 : (!torch.int, !torch.int, !torch.int) -> !torch.list<int>
  %139 = torch.aten.view %137, %138 : !torch.vtensor<[?,256],f32>, !torch.list<int> -> !torch.vtensor<[1,?,256],f32>
  return %139 : !torch.vtensor<[1,?,256],f32>
}